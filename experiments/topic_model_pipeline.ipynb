{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BERTopic Topic Modeling with Different Transformers\n",
        "This notebook compares different encoder models using BERTopic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from bertopic import BERTopic\n",
        "from bertopic.evaluation import coherence_score, diversity_score\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import pandas as pd\n",
        "\n",
        "class HFTransformerEmbedder:\n",
        "    def __init__(self, model_name, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name).to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def encode(self, texts, batch_size=16):\n",
        "        embeddings = []\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch = texts[i:i+batch_size]\n",
        "            inputs = self.tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(self.device)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                pooled = outputs.last_hidden_state.mean(dim=1)\n",
        "            embeddings.extend(pooled.cpu().numpy())\n",
        "        return embeddings\n",
        "\n",
        "def run_pipeline(texts, encoders):\n",
        "    results = []\n",
        "    for enc in encoders:\n",
        "        name, enc_type = enc['name'], enc['type']\n",
        "        print(f\"\\nRunning BERTopic with encoder: {name}\")\n",
        "        if enc_type == \"sentence-transformer\":\n",
        "            embedder = SentenceTransformer(name)\n",
        "        elif enc_type == \"huggingface\":\n",
        "            embedder = HFTransformerEmbedder(name).encode\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        topic_model = BERTopic(embedding_model=embedder, verbose=True)\n",
        "        topics, _ = topic_model.fit_transform(texts)\n",
        "\n",
        "        coherence = coherence_score(topic_model, texts, 'c_v')\n",
        "        diversity = diversity_score(topic_model)\n",
        "\n",
        "        results.append({\n",
        "            \"encoder\": name,\n",
        "            \"type\": enc_type,\n",
        "            \"coherence\": coherence,\n",
        "            \"diversity\": diversity,\n",
        "            \"num_topics\": len(set(topics)) - (1 if -1 in topics else 0)\n",
        "        })\n",
        "\n",
        "        topic_model.save(f\"models/bertopic_{name.replace('/', '_')}\")\n",
        "    return pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "texts = [\n",
        "    \"Climate change is real.\",\n",
        "    \"Artificial intelligence is transforming healthcare.\",\n",
        "    \"Elections are coming soon.\",\n",
        "    \"New technology in robotics.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of encoders\n",
        "encoders = [\n",
        "    {\"name\": \"all-MiniLM-L6-v2\", \"type\": \"sentence-transformer\"},\n",
        "    {\"name\": \"google/gemma-2b\", \"type\": \"huggingface\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "df_results = run_pipeline(texts, encoders)\n",
        "df_results.to_csv(\"results.csv\", index=False)\n",
        "df_results"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bertopic",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
